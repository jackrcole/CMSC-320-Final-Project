# Introduction {#intro}

Welcome to our guide!

From big data to machine learning, as data science becomes an area of ever-increasing importance, it is essential for people to gain an understanding of the foundational theory and applications of data science. Whether it's for a job, freelancing, or personal fun, our aim is to teach you the basics so you can make beautiful data representations like this:

```{r nice-fig, fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center'}
par(mar = c(4, 4, .1, .1))
plot(pressure, type = 'b', pch = 19)
```

For this guide, we'll be using R, and our dataset will be Kaggle's global terrorism database, which can be accessed from here: https://www.kaggle.com/START-UMD/gtd?select=globalterrorismdb_0718dist.csv.

# Getting Started

First, put the tidyverse library into your R file.

```{r lib}
library(tidyverse)
```

This library comes with a variety of functions and operators to make data manipulation and tidying easier. For a comprehensive overview, see here: https://medium.com/@brianward1428/introduction-to-tidyverse-7b3dbf2337d5.

Next, download the csv file onto your machine. To access it, set the working directory to the directory the file is in, and read it into a data frame with a variable name ("df" in the example below):

```{r data}
setwd("C:/Users/Amit/Documents/Final Project/Global Terrorism")  ## Use the setwd() function and the path to change directories
df <- read.csv("globalterrorismdb_0718dist.csv")                 ## Use the read.csv() function with the file name to access csv file
head(df)                                                         ## Show top of df
```

As you can see, there is a lot of data to parse. But don't worry: we have tools to help us.

## Pipelines and Basic Functions

Some basic operations for R include:

-select() -> selects specific vertical columns in the dataset
-slice() -> selects specific horizontal rows in a dataset
-filter() -> selects specific rows in a dataset based on a specific value in a column
-mutate() -> add a new column to the existing dataset
-arrange() -> sort entities within a column
-summarize() -> creates a new table with summaries of the columns in the original dataset

One concept in data science is the use of a pipeline, which looks like "%>%" in R. This bit of "syntactic sugar" makes it easier to understand how the data is being manipulated. Here's some examples with the above functions:

```{r expl}

```
