# Introduction {#intro}

Welcome to our guide!

From big data to machine learning, as data science becomes an area of ever-increasing importance, it is essential for people to gain an understanding of the foundational theory and applications of data science. Whether it's for a job, freelancing, or personal fun, our aim is to teach you the basics so you can make beautiful data representations like this:

```{r nice-fig, fig.cap='Here is a nice figure!', out.width='80%', fig.asp=.75, fig.align='center'}
par(mar = c(4, 4, .1, .1))
plot(pressure, type = 'b', pch = 19)
```

For this guide, we'll be using R, and our dataset will be Kaggle's global terrorism database, which can be accessed from here: https://www.kaggle.com/START-UMD/gtd?select=globalterrorismdb_0718dist.csv.

## Getting Started

First, put the tidyverse library into your R file.

```{r lib}
library(tidyverse)
```

This library comes with a variety of functions and operators to make data manipulation and tidying easier. For a comprehensive overview, see here: https://medium.com/@brianward1428/introduction-to-tidyverse-7b3dbf2337d5.

Next, download the csv file onto your machine. To access it, set the working directory to the directory the file is in, and read it into a data frame with a variable name ("df" in the example below):

```{r data}
setwd("C:/Users/Amit/Documents/Final Project/Global Terrorism")  ## Use the setwd() function and the path to change directories
df <- read.csv("globalterrorismdb_0718dist.csv")                 ## Use the read.csv() function with the file name to access csv file
head(df)                                                         ## Show top of df
```

As you can see, there is a lot of data to parse. But don't worry: we have tools to help us.

## Pipelines and Basic Functions

Some basic operations for R include:

-select() -> selects specific vertical columns in the dataset
-slice() -> selects specific horizontal rows in a dataset
-filter() -> selects specific rows in a dataset based on a specific value in a column
-mutate() -> add a new column to a dataset
-arrange() -> sort entities within a column
-summarize() -> creates a new table with summaries of the columns in the original dataset

One concept in data science is the use of a pipeline, which looks like "%>%" in R. This bit of "syntactic sugar" makes it easier to understand how the data is being manipulated. Here's some examples with the above functions:

```{r expl1}
# Data with attacks from September 1971
acts_sep71 <- df %>%            ## From df, have all occurances where iyear is 1971 and imonth is 9
  filter(iyear == 1971) %>%     ## This line filters out all years that are not 1971
  filter(imonth == 9)           ## This line filters out all months that are not 9 (Sept.)
head(acts_sep71)
```

```{r expl2}
# From September 1971 attacks, get coordinates of each attack
sep71_coord <- acts_sep71 %>%                         ## From acts_sep71...
  select(eventid, country_txt, latitude, longitude)   ## Select the eventid, country_txt, latitude, and longitude columns
head(sept71_coord)
```

```{r expl 3}
# From the previous data frame, order the countries alphabetically and select the top 10
coords10 <- sep71_coord %>%     ## From set71_coord...
  arrange(country_txt) %>%      ## arrange the country names in alphabetical order
  slice(1:10)                   ## select the ten terror acts at the top
coords10
```

```{r expl4}
# Summarize a few attributes of the September 1971 attacks
data_summary <- acts_sep71 %>%                                            ## From dataset, summarize mean success rate...
  summarize(success_rate = mean(success), half_way_day = median(iday))    ## ...and day where data can be split in two
data_summary
```
For more reading on the basic operations (plus some extra), see here: https://www.hcbravo.org/IntroDataSci/bookdown-notes/principles-basic-operations.html.

## Data Cleaning

In data science, the way data is presented is important to the understanding of the data itself. Confusing variables or missing variables can negatively impact the understanding of what the data is trying to convey. Therefore, it is important to fix these errors when they arise.

Here are some examples:

```{r no_nas}
## Clean up NA's from coords10 dataset
clean_coords10 <- sep71_coord %>%
  filter(!is.na(latitude)) %>%      ## Same as coords10, except all instances of NA in lat/long are filtered out
  arrange(country_txt) %>%
  slice(1:10)
clean_coords10
```

```{r to_true}
# Change success column values from 1/0 to TRUE/FALSE to ease readibility for success, multiple, and suicide
attrs <- c("multiple", "success", "suicide")            ## List of column names to change

for (name in attrs) {                                   ## In for loop, loop for every name              
  column <- acts_sep71[[name]]                          ## Select column with the name
  repl <- c()                                           ## Make a replacement vector "repl"
  for (x in column) {                                   ## In inner for loop, iterate over every element in selected column
    if (x == 1) {                                       ## Change 1 to TRUE
      repl <- c(repl, TRUE)                             ## Add to repl
    } else {                                            ## Change 0 to FALSE
      repl <- c(repl, FALSE)                            ## Add to repl
    }
  }
  if (length(repl) > length(acts_sep71$eventid)) {      ## If length of repl overshoots by 1 (can happen)
    repl <- repl %>% head(-1)                           ## Get rid of last element
  }
  acts_sep71[[name]] <- repl                            ## Replace old column with replacement
}

# Check
check <- acts_sep71 %>% 
  select(multiple, success, suicide)
head(check)
```

There are also other ways to clean this dataset, such as getting rid of unused columns. For more data cleaning techniques, see here: https://www.hcbravo.org/IntroDataSci/bookdown-notes/tidying-data.html.

## Parsing and Management

